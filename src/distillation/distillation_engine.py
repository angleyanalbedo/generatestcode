import asyncio
import json
import logging
import random
import os
from datetime import datetime
from typing import List, Dict, Set, Optional, Any

from src.llmclient import LLMClient

# å°è¯•å¯¼å…¥å¼‚æ­¥æ–‡ä»¶åº“
try:
    import aiofiles
    HAS_AIOFILES = True
except ImportError:
    HAS_AIOFILES = False

# å‡è®¾è¿™äº›æ˜¯ä½ å·²ç»å®šä¹‰çš„å¤–éƒ¨ç±»
from src.prompt_manager import PromptManager
from src.config_manager import ConfigManager
# ğŸŸ¢ ç¡®ä¿ä½ çš„éªŒè¯å™¨è·¯å¾„æ˜¯æ­£ç¡®çš„ï¼Œå¦‚æœå¼•å…¥äº† STParser è¯·åœ¨è¿™é‡Œå¯¼å…¥
from src.stvailder.stvailder import STValidator
# from src.stvailder import FastValidator 

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("DistillEngine")

class IOHandler:
    """è´Ÿè´£æ‰€æœ‰çš„æ–‡ä»¶è¯»å†™æ“ä½œã€å†…å­˜å»é‡é€»è¾‘å’Œ Golden Memory ç»´æŠ¤ã€‚"""
    def __init__(self, config: ConfigManager):
        self.cfg = config
        
        # å…¼å®¹ä½ ç°æœ‰çš„ config è¯»å–æ–¹å¼ï¼Œå¦‚æœæ²¡æœ‰ç›´æ¥ç”¨ hasattr ä¿æŠ¤
        self.output_file = config.get_path('output_file') if hasattr(config, 'get_path') else getattr(config, 'output_file', 'st_dataset.jsonl')
        self.dpo_file = config.get_path('dpo_file') if hasattr(config, 'get_path') else getattr(config, 'dpo_file', 'st_dpo.jsonl')
        self.golden_file = config.get_path('golden_file') if hasattr(config, 'get_path') else getattr(config, 'golden_file', 'golden.json')
        self.history_file = config.get_path('history_file') if hasattr(config, 'get_path') else getattr(config, 'history_file', 'history.jsonl')
        self.error_log_file = getattr(config, 'error_log_file', 'error_log.jsonl')
        self.failed_file = getattr(config, 'failed_file', 'failed_tasks.jsonl')

        self.io_lock = asyncio.Lock()
        self.golden_lock = asyncio.Lock()

        self.existing_tasks: Set[str] = set()
        self.golden_examples: List[Dict] = []

        self._load_data_sync()

    def _load_data_sync(self):
        count = 0
        for fpath in [self.history_file, self.output_file]:
            if fpath and os.path.exists(fpath):
                try:
                    with open(fpath, 'r', encoding='utf-8') as f:
                        for line in f:
                            try:
                                data = json.loads(line)
                                if "instruction" in data:
                                    task = data['instruction'].split("for: ")[-1]
                                    self.existing_tasks.add(task)
                                    count += 1
                            except: pass
                except Exception as e:
                    logger.warning(f"Error loading {fpath}: {e}")

        logger.info(f"ğŸ“‚ [Storage] Deduplication database built. Total: {count} tasks.")

        if self.golden_file and os.path.exists(self.golden_file):
            try:
                with open(self.golden_file, 'r', encoding='utf-8') as f:
                    self.golden_examples = json.load(f)
                logger.info(f"ğŸ† [Storage] Loaded {len(self.golden_examples)} golden examples.")
            except: pass

    async def is_duplicate(self, task: str) -> bool: return task in self.existing_tasks
    async def add_task_record(self, task: str): self.existing_tasks.add(task)

    async def get_random_golden_example(self) -> Optional[Dict]:
        async with self.golden_lock:
            return random.choice(self.golden_examples) if self.golden_examples else None

    async def update_golden(self, task: str, code: str):
        if not (200 < len(code) < 2000): return
        async with self.golden_lock:
            self.golden_examples.append({"task": task, "code": code})
            if len(self.golden_examples) > 50:
                self.golden_examples.pop(0)
            await self._write_json(self.golden_file, self.golden_examples, mode='w')

    async def save_success(self, data: Dict): await self._write_line(self.output_file, data)

    async def save_failed_record(self, data: dict):
        record = {
            "timestamp": datetime.now().isoformat(),
            "task_context": data.get("task"),
            "error_type": data.get("type", "exception_failure"),
            "error_detail": data.get("error"),
            "last_code_snippet": data.get("code")
        }
        await self._write_line(self.error_log_file, record)

    async def save_failed_task(self, data: dict):
        data["timestamp"] = datetime.now().isoformat()
        await self._write_line(self.failed_file, data)

    async def save_dpo(self, task: str, chosen: str, rejected: str, metadata: Dict):
        entry = {
            "prompt": f"Write ST code for: {task}",
            "chosen": chosen,
            "rejected": rejected,
            "metadata": metadata
        }
        await self._write_line(self.dpo_file, entry)

    async def _write_line(self, filepath: str, data: Dict):
        line = json.dumps(data, ensure_ascii=False) + "\n"
        async with self.io_lock:
            if HAS_AIOFILES:
                async with aiofiles.open(filepath, 'a', encoding='utf-8') as f:
                    await f.write(line)
            else:
                with open(filepath, 'a', encoding='utf-8') as f:
                    f.write(line)

    async def _write_json(self, filepath: str, data: Any, mode='w'):
        content = json.dumps(data, ensure_ascii=False, indent=2)
        if HAS_AIOFILES:
            async with aiofiles.open(filepath, mode, encoding='utf-8') as f:
                await f.write(content)
        else:
            with open(filepath, mode, encoding='utf-8') as f:
                f.write(content)

    def current_count(self): return len(self.existing_tasks)

class AsyncSTDistillationEngine:
    """æ ¸å¿ƒç¼–æ’è€…"""
    def __init__(self, config: ConfigManager, prompts: PromptManager, client: LLMClient):
        self.cfg = config
        self.prompts = prompts
        self.task_queue = asyncio.Queue(maxsize=500)
        self.use_strict = getattr(config, 'use_strict', True)

        self.validator = STValidator()
        # self.fast_validator = FastValidator() # æŒ‰éœ€å¯ç”¨
        
        self.io = IOHandler(config)
        self.llm_client = client

        self.semaphore = asyncio.Semaphore(config.max_concurrency)
        self.running_tasks = set()

    def _validate_st_syntax(self, code: str) -> tuple[bool, str]:
        # ä¿æŒä½ ç°æœ‰çš„è°ƒç”¨æ–¹å¼
        return self.validator.validate(code) # æˆ–è€… validate_v2ï¼Œçœ‹ä½ å®é™…çš„æ–¹æ³•å

    async def _step_brainstorm(self) -> List[str]:
        domains = ["Motion Control", "Safety Logic", "Closed Loop Control", "Data Processing", "Communication"]
        industries = ["Packaging", "Pharma", "Automotive", "Water Treatment"]
        topic = f"{random.choice(domains)} in {random.choice(industries)}"

        try:
            messages = self.prompts.get_brainstorm_messages(topic, count=10)
            response = await self.llm_client.chat(messages=messages, temperature=0.7, json_mode=True)
            
            # å®‰å…¨æå–åˆ—è¡¨
            tasks = []
            if isinstance(response, list):
                tasks = response
            elif isinstance(response, dict):
                tasks = response.get("tasks", [])
                if not tasks and len(response) > 0:
                    tasks = next(iter(response.values()))

            return [t for t in tasks if isinstance(t, str) and len(t) > 10]
        except Exception as e:
            logger.warning(f"Brainstorm failed: {str(e)[:50]}")
            return []

    async def _task_producer(self):
        target_count = getattr(self.cfg, 'target_count', 200000)
        while self.io.current_count() < target_count:
            if self.task_queue.qsize() < 500:
                new_tasks = await self._step_brainstorm()
                for t in new_tasks:
                    if not await self.io.is_duplicate(t):
                        await self.task_queue.put(t)
            else:
                await asyncio.sleep(1)

    async def _step_evolve(self, base_task: str) -> str:
        if random.random() > 0.7: return base_task 
        try:
            messages = self.prompts.get_evolution_prompt(base_task)
            if isinstance(messages, str):
                messages = [{"role": "user", "content": f"{messages}\nOutput ONLY the new task string."}]
            response = await self.llm_client.chat(json_mode=False, messages=messages, temperature=0.8)
            return response.strip()
        except: return base_task

    async def _step_critique(self, task: str, code: str) -> Dict:
        try:
            messages = self.prompts.get_critique_messages(task, code)
            response = await self.llm_client.chat(messages=messages, temperature=0.1, json_mode=True)
            if isinstance(response, dict):
                return response
            return {"passed": True, "reason": "Review format error"}
        except: return {"passed": True, "reason": "Reviewer Failed"}

    async def _process_single_task(self, raw_task: str):
        if await self.io.is_duplicate(raw_task): return

        async with self.semaphore:
            task = await self._step_evolve(raw_task)
            golden_example = await self.io.get_random_golden_example()
            messages = self.prompts.get_generation_messages(task, golden_example=golden_example)
            rejected_history = []
            max_retries = getattr(self.cfg, 'max_retries', 3)

            for attempt in range(max_retries):
                try:
                    response = await self.llm_client.chat(messages=messages, temperature=0.5, json_mode=True)
                    
                    if not isinstance(response, dict):
                        raise ValueError("Model returned invalid JSON structure.")
                        
                    code = response.get('code', '')
                    thought = response.get('thought', '')

                    # 1: é™æ€è¯­æ³•éªŒè¯
                    is_valid, error_msg = self._validate_st_syntax(code)

                    if not is_valid:
                        rejected_history.append({"code": code, "error": error_msg})
                        messages.append({"role": "assistant", "content": code})
                        messages.append({"role": "user", "content": f"Syntax Error: {error_msg}. Fix it."})
                        continue

                    # 2: AI é€»è¾‘å®¡æŸ¥
                    review = await self._step_critique(task, code)

                    if review.get('passed', True):
                        # === æˆåŠŸè·¯å¾„ ===
                        result_data = {
                            "instruction": f"Write an IEC 61131-3 Structured Text function block for: {task}",
                            "output": code,
                            "metadata": {
                                "thought": thought,
                                "retries": attempt,
                                "evolution": "evolved" if task != raw_task else "base"
                            }
                        }
                        await self.io.save_success(result_data)

                        if rejected_history:
                            await self.io.save_dpo(task, code, rejected_history[-1]["code"], {"type": "self_correction"})

                        await self.io.update_golden(task, code)
                        await self.io.add_task_record(raw_task)

                        logger.info(f"âœ… Finished: {task[:40]}... (Try {attempt + 1})")
                        return

                    else:
                        # === é€»è¾‘å¤±è´¥è·¯å¾„ ===
                        rejected_history.append({"code": code, "error": review.get('reason')})
                        messages.append({"role": "assistant", "content": code})
                        messages.append({"role": "user", "content": f"Logic Error: {review['reason']}. Fix it."})

                except Exception as e:
                    error_msg = str(e)
                    # å¤„ç†æ‰€æœ‰ Key è€—å°½çš„è‡´å‘½é”™è¯¯
                    if "ALL_KEYS_EXHAUSTED" in error_msg:
                        logger.error(f"ğŸš¨ è‡´å‘½é”™è¯¯ï¼šæ‰€æœ‰ Key å‡å·²è€—å°½ï¼åœæ­¢é‡è¯•ã€‚")
                        break 
                        
                    if attempt == max_retries - 1:
                        logger.error(f"âŒ æœ€ç»ˆå°è¯•å¤±è´¥: {error_msg[:50]}")
                        if 'code' in locals() and code:
                            await self.io.save_failed_record({
                                "task": task, "code": code, "error": error_msg, "type": "exception_failure"
                            })
                    else:
                        logger.warning(f"âš ï¸ [é‡è¯• {attempt+1}/{max_retries}] ç”Ÿæˆé‡æŒ«: {error_msg[:50]}")
                        await asyncio.sleep(2)

            # === å½»åº•å¤±è´¥è·¯å¾„ ===
            if rejected_history:
                await self.io.save_failed_task({
                    "instruction": task,
                    "rejected_samples": rejected_history,
                    "final_reason": "Exhausted retries"
                })

    async def run(self):
        target_count = getattr(self.cfg, 'target_count', 200000)
        logger.info(f"ğŸš€ Engine Started | Target: {target_count} | Concurrency: {self.cfg.max_concurrency}")

        producer_task = asyncio.create_task(self._task_producer())
        pending_tasks = set()

        while self.io.current_count() < target_count:
            if len(pending_tasks) < self.cfg.max_concurrency * 1.5:
                # ä»ç”Ÿäº§è€…çš„é˜Ÿåˆ—é‡Œæ‹¿é¢˜ç›®
                if not self.task_queue.empty():
                    t = await self.task_queue.get()
                    task_coro = asyncio.create_task(self._process_single_task(t))
                    pending_tasks.add(task_coro)
                    task_coro.add_done_callback(pending_tasks.discard)

            if self.io.current_count() % 10 == 0:
                print(f"ğŸ’“ Progress: {self.io.current_count()}/{target_count} | Running: {len(pending_tasks)}", end='\r')

            await asyncio.sleep(0.5)

        if pending_tasks:
            await asyncio.gather(*pending_tasks)
        logger.info("ğŸ‰ Distillation Complete!")