import argparse
import json
import os
from pathlib import Path
from typing import Tuple, List, Dict

from tqdm import tqdm

from src.stvailder import STValidator


class STDataCleaner:
    def __init__(self, input_dir: str, output_dir: str,mode: bool, ext: str = ".json"):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.ext = ext
        self.strict_mode = mode
        self.validator = STValidator()

        # å‡†å¤‡è¾“å‡ºç›®å½•ç»“æ„
        self.valid_dir = self.output_dir / "valid"
        self.invalid_dir = self.output_dir / "invalid"
        self.valid_dir.mkdir(parents=True, exist_ok=True)
        self.invalid_dir.mkdir(parents=True, exist_ok=True)

        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            "total_files": 0,
            "processed_files": 0,
            "total_samples": 0,
            "valid_samples": 0,
            "invalid_samples": 0
        }

    def auto_repair(self, code: str) -> str:
        """å°è¯•è‡ªåŠ¨ä¿®å¤å’Œæå–çº¯å‡€çš„ ST ä»£ç ï¼Œé˜²æ­¢å› ä¸ºå¤šä½™çš„å­—ç¬¦å¯¼è‡´ AST è§£æå¤±è´¥"""
        if not code:
            return ""

        # 1. å‰¥ç¦» Markdown åŒ…è£… (å¾ˆå¤šæ•°æ®é›†å¸¦æœ‰ ```st ... ```)
        import re
        # æå– ``` ä¹‹é—´çš„å†…å®¹
        md_match = re.search(r"```[a-zA-Z]*\n(.*?)```", code, re.DOTALL | re.IGNORECASE)
        if md_match:
            code = md_match.group(1)

        # 2. å°è¯•è¿‡æ»¤æ‰å¼€å¤´çš„è‡ªç„¶è¯­è¨€åºŸè¯ (æ¯”å¦‚ "Here is the code:\n")
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå…³é”®å­—çš„ä½ç½®
        keywords = ["FUNCTION_BLOCK", "FUNCTION", "PROGRAM", "VAR", "TYPE"]
        first_idx = len(code)
        for kw in keywords:
            idx = code.upper().find(kw)
            if idx != -1 and idx < first_idx:
                first_idx = idx

        if first_idx != len(code) and first_idx > 0:
            code = code[first_idx:]

        return code.strip()

    def process_single_file(self, file_path: Path, strict_mode: bool = False) -> Tuple[List[Dict], List[Dict]]:
        """å¤„ç†å•ä¸ª JSON æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        valid_data, invalid_data = [], []

        for item in data:
            self.stats["total_samples"] += 1
            original_code = item.get("output", "")

            # ğŸš€ ç¬¬ä¸€æ­¥ï¼šè‡ªåŠ¨æŠ¢æ•‘ä»£ç æ ¼å¼
            repaired_code = self.auto_repair(original_code)

            # å¦‚æœä¿®å¤åä»£ç æœ‰å˜åŒ–ï¼Œæ›´æ–°å› item
            if repaired_code != original_code:
                item["output"] = repaired_code
                item["was_repaired"] = True

            # ğŸš€ ç¬¬äºŒæ­¥ï¼šçº§è”æ ¡éªŒå¹¶æ‰“æ ‡
            status = "golden"
            error_reason = None

            if not repaired_code:
                status = "empty"
                error_reason = "No code found after repair"
            else:
                # æ ¡éªŒé˜¶æ®µ 1: é™æ€æ­£åˆ™æ ¡éªŒ
                is_valid_s1, msg1 = self.validator.validate(repaired_code)
                if not is_valid_s1:
                    status = "syntax_error"
                    error_reason = msg1
                else:
                    # æ ¡éªŒé˜¶æ®µ 2: AST è¯­ä¹‰æ ¡éªŒ
                    is_valid_s2, msg2 = self.validator.validate_v2(repaired_code)
                    if not is_valid_s2:
                        status = "ast_error"
                        error_reason = msg2

            # ğŸš€ ç¬¬ä¸‰æ­¥ï¼šæ ¹æ®æ¨¡å¼å†³å®šå»ç•™
            # è®°å½•å…ƒæ•°æ®
            item["st_metadata"] = {
                "quality": status,
                "error": error_reason
            }

            if strict_mode:
                # ä¸¥æ ¼æ¨¡å¼ï¼šç¨å¾®æœ‰é”™å°±æ‰”è¿› invalid
                if status == "golden":
                    valid_data.append(item)
                else:
                    invalid_data.append(item)
            else:
                # è½¯æ¨¡å¼ï¼šå…¨éƒ¨æ”¾è¿› validï¼Œç”±åç»­ç®¡çº¿æ ¹æ® quality æ ‡ç­¾è‡ªè¡Œå†³å®šæ€ä¹ˆç”¨
                valid_data.append(item)

        self.stats["valid_samples"] += len(valid_data)
        self.stats["invalid_samples"] += len(invalid_data)
        return valid_data, invalid_data

    def run(self):
        """æ‰§è¡Œæ‰¹é‡æ¸…æ´—æµç¨‹"""
        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
        files = list(self.input_dir.rglob(f"*{self.ext}"))
        self.stats["total_files"] = len(files)

        if not files:
            print(f"âŒ åœ¨ {self.input_dir} ä¸­æœªæ‰¾åˆ°ä»»ä½• {self.ext} æ–‡ä»¶ï¼")
            return

        print(f"ğŸš€ å‘ç° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡æ¸…æ´—...")

        # å¸¦è¿›åº¦æ¡éå†æ–‡ä»¶
        for file_path in tqdm(files, desc="Processing Files"):
            valid_list, invalid_list = self.process_single_file(file_path,self.strict_mode)

            # åªæœ‰å¤„ç†æˆåŠŸæ‰ç®—ä¸€ä¸ªæœ‰æ•ˆæ–‡ä»¶
            if valid_list or invalid_list:
                self.stats["processed_files"] += 1

                # åˆ†åˆ«è½ç›˜ä¿å­˜ (ä¿æŒåŸæ–‡ä»¶å)
                if valid_list:
                    out_valid = self.valid_dir / file_path.name
                    with open(out_valid, 'w', encoding='utf-8') as f:
                        json.dump(valid_list, f, ensure_ascii=False, indent=2)

                if invalid_list:
                    out_invalid = self.invalid_dir / f"rejected_{file_path.name}"
                    with open(out_invalid, 'w', encoding='utf-8') as f:
                        json.dump(invalid_list, f, ensure_ascii=False, indent=2)

        self.print_report()

    def print_report(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š"""
        total = self.stats["total_samples"]
        valid = self.stats["valid_samples"]
        invalid = self.stats["invalid_samples"]
        pass_rate = (valid / total * 100) if total > 0 else 0

        print("\n" + "=" * 50)
        print("ğŸ“Š ST æ•°æ®é›†æ‰¹é‡æ¸…æ´—æŠ¥å‘Š")
        print("=" * 50)
        print(f"ğŸ“‚ æ‰«ææ–‡ä»¶æ•°: {self.stats['total_files']} (æˆåŠŸå¤„ç†: {self.stats['processed_files']})")
        print(f"ğŸ“¦ æ€»æ ·æœ¬æ•°:   {total}")
        print(f"âœ… åˆæ ¼æ ·æœ¬:   {valid} ({pass_rate:.2f}%)")
        print(f"âŒ æ·˜æ±°æ ·æœ¬:   {invalid} ({(100 - pass_rate):.2f}%)")
        print("-" * 50)
        print(f"ğŸ“ é»„é‡‘æ•°æ®å­˜æ”¾è‡³: {self.valid_dir.absolute()}")
        print(f"ğŸ“ åƒåœ¾æ•°æ®å­˜æ”¾è‡³: {self.invalid_dir.absolute()}")
        print("=" * 50)


def parse_args():
    parser = argparse.ArgumentParser(description="STä»£ç æ•°æ®é›†æ‰¹é‡æ¸…æ´—å·¥å…· (ST Validator CLI)")
    parser.add_argument("-i", "--input_dir", type=str, required=True,
                        help="åŒ…å«åŸå§‹ JSON æ•°æ®é›†çš„è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("-o", "--output_dir", type=str, required=True,
                        help="æ¸…æ´—åæ•°æ®çš„è¾“å‡ºæ ¹ç›®å½•")
    parser.add_argument("-e", "--ext", type=str, default=".json",
                        help="è¦å¤„ç†çš„æ–‡ä»¶æ‰©å±•å (é»˜è®¤: .json)")
    parser.add_argument("--strict", action="store_true",
                        help="å¼€å¯ä¸¥æ ¼æ¨¡å¼ï¼šä¸¢å¼ƒæ‰€æœ‰æœªé€šè¿‡æ ¡éªŒçš„æ•°æ®ã€‚ä¸åŠ æ­¤å‚æ•°åˆ™ä¸ºè½¯æ‰“æ ‡æ¨¡å¼ã€‚")
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()

    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.isdir(args.input_dir):
        print(f"âŒ é”™è¯¯: è¾“å…¥ç›®å½• '{args.input_dir}' ä¸å­˜åœ¨ï¼")
        exit(1)

    cleaner = STDataCleaner(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        ext=args.ext,
        mode=args.strict
    )
    cleaner.run()